{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:52:21.255274Z",
     "start_time": "2024-09-03T07:52:19.993302Z"
    }
   },
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain langchain-openai langchain-openai langchain_chroma langchain-text-splitters langchain_community faiss-cpu"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:52:22.063108Z",
     "start_time": "2024-09-03T07:52:21.259441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "\n",
    "example_messages"
   ],
   "id": "687a562ba1281dee",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/langsmith/client.py:333: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: filler question \\nContext: filler context \\nAnswer:\")]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:52:22.077293Z",
     "start_time": "2024-09-03T07:52:22.075254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]"
   ],
   "id": "11d7ecb3bee01503",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:52:22.495292Z",
     "start_time": "2024-09-03T07:52:22.086589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(urls)\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ],
   "id": "d9fb6784cacb9bdc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2731, which is longer than the specified 1000\n",
      "Created a chunk of size 1538, which is longer than the specified 1000\n",
      "Created a chunk of size 1380, which is longer than the specified 1000\n",
      "Created a chunk of size 2352, which is longer than the specified 1000\n",
      "Created a chunk of size 1953, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1475, which is longer than the specified 1000\n",
      "Created a chunk of size 2881, which is longer than the specified 1000\n",
      "Created a chunk of size 1980, which is longer than the specified 1000\n",
      "Created a chunk of size 4145, which is longer than the specified 1000\n",
      "Created a chunk of size 2528, which is longer than the specified 1000\n",
      "Created a chunk of size 2158, which is longer than the specified 1000\n",
      "Created a chunk of size 1317, which is longer than the specified 1000\n",
      "Created a chunk of size 1112, which is longer than the specified 1000\n",
      "Created a chunk of size 1043, which is longer than the specified 1000\n",
      "Created a chunk of size 1578, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 3028, which is longer than the specified 1000\n",
      "Created a chunk of size 1463, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 1743, which is longer than the specified 1000\n",
      "Created a chunk of size 2407, which is longer than the specified 1000\n",
      "Created a chunk of size 1682, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1036, which is longer than the specified 1000\n",
      "Created a chunk of size 1214, which is longer than the specified 1000\n",
      "Created a chunk of size 1189, which is longer than the specified 1000\n",
      "Created a chunk of size 1986, which is longer than the specified 1000\n",
      "Created a chunk of size 1084, which is longer than the specified 1000\n",
      "Created a chunk of size 1278, which is longer than the specified 1000\n",
      "Created a chunk of size 1462, which is longer than the specified 1000\n",
      "Created a chunk of size 3160, which is longer than the specified 1000\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:52:24.908136Z",
     "start_time": "2024-09-03T07:52:22.502865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)"
   ],
   "id": "a3f67193d0d9f6ce",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:52:24.921278Z",
     "start_time": "2024-09-03T07:52:24.918033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_query = \"agent memory\"\n",
    "\n",
    "vector_store_retrievers = [vectorstore.as_retriever(), vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
    "), vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 5, 'fetch_k': 50}\n",
    "), vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={'score_threshold': 0.8}\n",
    "), vectorstore.as_retriever(search_kwargs={'k': 1}), vectorstore.as_retriever(\n",
    "    search_kwargs={'filter': {'paper_title': 'GPT-4 Technical Report'}}\n",
    ")]"
   ],
   "id": "93758dca19ba1203",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:52:38.408989Z",
     "start_time": "2024-09-03T07:52:24.930657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "relevant_prompt = PromptTemplate(\n",
    "    template=\"Determine if the query is relevant to docs.\\n{format_instructions}\\n{query}\\n{docs}\",\n",
    "    input_variables=[\"query\", \"docs\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "relevant_chain = relevant_prompt | llm | parser\n",
    "\n",
    "relevant_retrievers = []\n",
    "irrelevant_retrievers = []\n",
    "\n",
    "for retriever in vector_store_retrievers:\n",
    "    docs = retriever.invoke(user_query)\n",
    "    res = relevant_chain.invoke({\"query\": user_query, \"docs\": docs})\n",
    "    print(res)\n",
    "    if res.get('relevant', False):\n",
    "        relevant_retrievers.append(retriever)\n",
    "    else:\n",
    "        irrelevant_retrievers.append(retriever)"
   ],
   "id": "ffe4329d0a28e065",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevant': True, 'explanation': \"The query 'agent memory' is relevant to the documents as they discuss the concept of LLM-powered autonomous agents, including various components such as memory systems, task decomposition, and the reflection mechanism, all of which are pertinent to the idea of memory in agent systems.\"}\n",
      "{'relevant': True, 'reason': \"The query 'agent memory' is relevant to the provided documents, particularly the one discussing LLM-powered autonomous agents which includes details about memory systems such as Short-Term Memory (STM), Long-Term Memory (LTM), and the role of memory in agent systems.\"}\n",
      "{'relevant': True, 'documents': [{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.', 'content': 'Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning...'}, {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.', 'content': 'The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]...'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isRelevant': False, 'message': \"The query 'agent memory' does not provide enough context to determine relevance to specific documents.\"}\n",
      "{'relevant': True}\n",
      "{'relevant': False, 'message': \"The query 'agent memory' is too vague and does not provide enough context to determine its relevance to specific documents.\"}\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:53:00.108509Z",
     "start_time": "2024-09-03T07:52:54.260434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relevant_checker = 'I like an apple'\n",
    "\n",
    "validated_retrievers = []\n",
    "\n",
    "for retriever in relevant_retrievers:\n",
    "    docs = retriever.invoke(relevant_checker)\n",
    "    res = relevant_chain.invoke({\"query\": relevant_checker, \"docs\": docs})\n",
    "    if not res.get('relevant', True):\n",
    "        print(\"Not relevant\")\n",
    "    else:\n",
    "        print(\"Relevant\")"
   ],
   "id": "5f000c8505647ff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not relevant\n",
      "Not relevant\n",
      "Not relevant\n",
      "Not relevant\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T08:12:03.464082Z",
     "start_time": "2024-09-03T08:12:00.625354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hallucination_prompt = PromptTemplate(\n",
    "    template=\"Determine if the query has hallucination or not.\\n{format_instructions}\\n{query}\\n{docs}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "hallucination_chain = hallucination_prompt | llm | parser\n",
    "\n",
    "for retriever in relevant_retrievers:\n",
    "    docs = retriever.invoke(user_query)\n",
    "    res = hallucination_chain.invoke({\"query\": user_query, \"docs\": docs})\n",
    "    \n",
    "    if res.get('hallucination', True):\n",
    "        break\n",
    "    else:\n",
    "        print(docs[0])"
   ],
   "id": "87a0cc7010b6a12c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}\n"
     ]
    }
   ],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3e5adf4dd897a43a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
