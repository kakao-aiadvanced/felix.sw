{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "nETMGv52qGnB",
    "ExecuteTime": {
     "end_time": "2024-09-02T09:43:35.151850Z",
     "start_time": "2024-09-02T09:43:30.357653Z"
    }
   },
   "source": [
    "!pip install promptbench openai==1.3.7"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting promptbench\r\n",
      "  Using cached promptbench-0.0.4-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting openai==1.3.7\r\n",
      "  Using cached openai-1.3.7-py3-none-any.whl.metadata (17 kB)\r\n",
      "Collecting anyio<4,>=3.5.0 (from openai==1.3.7)\r\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.3.7) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.3.7) (0.27.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.3.7) (2.5.3)\r\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.3.7) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.3.7) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.3.7) (4.11.0)\r\n",
      "Collecting autocorrect==2.6.1 (from promptbench)\r\n",
      "  Using cached autocorrect-2.6.1-py3-none-any.whl\r\n",
      "Collecting accelerate==0.25.0 (from promptbench)\r\n",
      "  Using cached accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting datasets>=2.15.0 (from promptbench)\r\n",
      "  Using cached datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: nltk==3.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from promptbench) (3.8.1)\r\n",
      "Collecting sentencepiece==0.1.99 (from promptbench)\r\n",
      "  Using cached sentencepiece-0.1.99.tar.gz (2.6 MB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting tokenizers==0.15.0 (from promptbench)\r\n",
      "  Using cached tokenizers-0.15.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Collecting torch>=2.1.1 (from promptbench)\r\n",
      "  Using cached torch-2.4.0-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\r\n",
      "Collecting tqdm>4 (from openai==1.3.7)\r\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "Collecting transformers==4.38.0 (from promptbench)\r\n",
      "  Using cached transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\r\n",
      "Requirement already satisfied: Pillow==10.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from promptbench) (10.3.0)\r\n",
      "Collecting google-generativeai==0.4.0 (from promptbench)\r\n",
      "  Using cached google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Collecting dashscope==1.14.1 (from promptbench)\r\n",
      "  Using cached dashscope-1.14.1-py3-none-any.whl.metadata (6.7 kB)\r\n",
      "Collecting einops==0.7.0 (from promptbench)\r\n",
      "  Using cached einops-0.7.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting transformers-stream-generator==0.0.5 (from promptbench)\r\n",
      "  Using cached transformers_stream_generator-0.0.5-py3-none-any.whl\r\n",
      "Collecting torchvision==0.17.0 (from promptbench)\r\n",
      "  Using cached torchvision-0.17.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Collecting matplotlib==3.8.3 (from promptbench)\r\n",
      "  Using cached matplotlib-3.8.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.8 kB)\r\n",
      "Collecting tiktoken==0.6.0 (from promptbench)\r\n",
      "  Using cached tiktoken-0.6.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate==0.25.0->promptbench) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate==0.25.0->promptbench) (23.2)\r\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from accelerate==0.25.0->promptbench) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from accelerate==0.25.0->promptbench) (6.0.1)\r\n",
      "Collecting huggingface-hub (from accelerate==0.25.0->promptbench)\r\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting safetensors>=0.3.1 (from accelerate==0.25.0->promptbench)\r\n",
      "  Using cached safetensors-0.4.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from dashscope==1.14.1->promptbench) (3.9.5)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from dashscope==1.14.1->promptbench) (2.32.2)\r\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Collecting google-api-core (from google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.4.0->promptbench) (3.20.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib==3.8.3->promptbench) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib==3.8.3->promptbench) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib==3.8.3->promptbench) (4.51.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib==3.8.3->promptbench) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib==3.8.3->promptbench) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib==3.8.3->promptbench) (2.9.0.post0)\r\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk==3.8.1->promptbench) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk==3.8.1->promptbench) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk==3.8.1->promptbench) (2023.10.3)\r\n",
      "Collecting torch>=2.1.1 (from promptbench)\r\n",
      "  Using cached torch-2.2.0-cp312-none-macosx_11_0_arm64.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.1.1->promptbench) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.1.1->promptbench) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.1.1->promptbench) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.1.1->promptbench) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.1.1->promptbench) (2024.3.1)\r\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<4,>=3.5.0->openai==1.3.7) (3.7)\r\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.15.0->promptbench)\r\n",
      "  Using cached pyarrow-17.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.15.0->promptbench) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.15.0->promptbench) (2.2.2)\r\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting datasets>=2.15.0 (from promptbench)\r\n",
      "  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting pyarrow-hotfix (from datasets>=2.15.0->promptbench)\r\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting datasets>=2.15.0 (from promptbench)\r\n",
      "  Using cached datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.15.0->promptbench) (14.0.2)\r\n",
      "Collecting xxhash (from datasets>=2.15.0->promptbench)\r\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess (from datasets>=2.15.0->promptbench)\r\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\r\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai==1.3.7) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai==1.3.7) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.7) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai==1.3.7) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai==1.3.7) (2.14.6)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope==1.14.1->promptbench) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope==1.14.1->promptbench) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope==1.14.1->promptbench) (1.4.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope==1.14.1->promptbench) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope==1.14.1->promptbench) (1.9.3)\r\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai==0.4.0->promptbench) (5.3.3)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai==0.4.0->promptbench) (0.2.8)\r\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.8.3->promptbench) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->dashscope==1.14.1->promptbench) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->dashscope==1.14.1->promptbench) (2.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.1.1->promptbench) (2.1.3)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets>=2.15.0->promptbench) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets>=2.15.0->promptbench) (2023.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch>=2.1.1->promptbench) (1.3.0)\r\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached grpcio-1.66.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.9 kB)\r\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.4.0->promptbench) (0.4.8)\r\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Using cached grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Using cached grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Using cached grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting protobuf (from google-generativeai==0.4.0->promptbench)\r\n",
      "  Using cached protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\r\n",
      "Using cached openai-1.3.7-py3-none-any.whl (221 kB)\r\n",
      "Using cached promptbench-0.0.4-py3-none-any.whl (129 kB)\r\n",
      "Using cached accelerate-0.25.0-py3-none-any.whl (265 kB)\r\n",
      "Using cached dashscope-1.14.1-py3-none-any.whl (1.2 MB)\r\n",
      "Using cached einops-0.7.0-py3-none-any.whl (44 kB)\r\n",
      "Using cached google_generativeai-0.4.0-py3-none-any.whl (137 kB)\r\n",
      "Using cached matplotlib-3.8.3-cp312-cp312-macosx_11_0_arm64.whl (7.5 MB)\r\n",
      "Using cached tiktoken-0.6.0-cp312-cp312-macosx_11_0_arm64.whl (922 kB)\r\n",
      "Using cached tokenizers-0.15.0-cp312-cp312-macosx_11_0_arm64.whl (2.5 MB)\r\n",
      "Using cached torchvision-0.17.0-cp312-cp312-macosx_11_0_arm64.whl (1.6 MB)\r\n",
      "Using cached torch-2.2.0-cp312-none-macosx_11_0_arm64.whl (59.7 MB)\r\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\r\n",
      "Using cached transformers-4.38.0-py3-none-any.whl (8.5 MB)\r\n",
      "Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\r\n",
      "Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\r\n",
      "Using cached datasets-2.19.2-py3-none-any.whl (542 kB)\r\n",
      "Using cached google_api_core-2.19.2-py3-none-any.whl (139 kB)\r\n",
      "Using cached google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\r\n",
      "Using cached huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\r\n",
      "Using cached safetensors-0.4.4-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\r\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\r\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
      "Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\r\n",
      "Using cached proto_plus-1.24.0-py3-none-any.whl (50 kB)\r\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\r\n",
      "Using cached grpcio-1.66.1-cp312-cp312-macosx_10_9_universal2.whl (10.6 MB)\r\n",
      "Using cached grpcio_status-1.62.3-py3-none-any.whl (14 kB)\r\n",
      "Using cached protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\r\n",
      "Building wheels for collected packages: sentencepiece\r\n",
      "  Building wheel for sentencepiece (setup.py) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py bdist_wheel\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[65 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m running bdist_wheel\r\n",
      "  \u001B[31m   \u001B[0m running build\r\n",
      "  \u001B[31m   \u001B[0m running build_py\r\n",
      "  \u001B[31m   \u001B[0m creating build\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.macosx-11.1-arm64-cpython-312\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.macosx-11.1-arm64-cpython-312/sentencepiece\r\n",
      "  \u001B[31m   \u001B[0m copying src/sentencepiece/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/sentencepiece\r\n",
      "  \u001B[31m   \u001B[0m copying src/sentencepiece/_version.py -> build/lib.macosx-11.1-arm64-cpython-312/sentencepiece\r\n",
      "  \u001B[31m   \u001B[0m copying src/sentencepiece/sentencepiece_model_pb2.py -> build/lib.macosx-11.1-arm64-cpython-312/sentencepiece\r\n",
      "  \u001B[31m   \u001B[0m copying src/sentencepiece/sentencepiece_pb2.py -> build/lib.macosx-11.1-arm64-cpython-312/sentencepiece\r\n",
      "  \u001B[31m   \u001B[0m running build_ext\r\n",
      "  \u001B[31m   \u001B[0m Package sentencepiece was not found in the pkg-config search path.\r\n",
      "  \u001B[31m   \u001B[0m Perhaps you should add the directory containing `sentencepiece.pc'\r\n",
      "  \u001B[31m   \u001B[0m to the PKG_CONFIG_PATH environment variable\r\n",
      "  \u001B[31m   \u001B[0m No package 'sentencepiece' found\r\n",
      "  \u001B[31m   \u001B[0m ./build_bundled.sh: line 21: cmake: command not found\r\n",
      "  \u001B[31m   \u001B[0m ./build_bundled.sh: line 22: cmake: command not found\r\n",
      "  \u001B[31m   \u001B[0m Traceback (most recent call last):\r\n",
      "  \u001B[31m   \u001B[0m   File \"<string>\", line 2, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/5r/4mv8lcp17z90z_5v5rd13sbr0000gn/T/pip-install-8z7a2wab/sentencepiece_3187d6fd723446f6a7e54c9688991d30/setup.py\", line 167, in <module>\r\n",
      "  \u001B[31m   \u001B[0m     setup(\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/__init__.py\", line 104, in setup\r\n",
      "  \u001B[31m   \u001B[0m     return distutils.core.setup(**attrs)\r\n",
      "  \u001B[31m   \u001B[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 184, in setup\r\n",
      "  \u001B[31m   \u001B[0m     return run_commands(dist)\r\n",
      "  \u001B[31m   \u001B[0m            ^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 200, in run_commands\r\n",
      "  \u001B[31m   \u001B[0m     dist.run_commands()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\r\n",
      "  \u001B[31m   \u001B[0m     self.run_command(cmd)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 967, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     super().run_command(command)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     cmd_obj.run()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/wheel/bdist_wheel.py\", line 368, in run\r\n",
      "  \u001B[31m   \u001B[0m     self.run_command(\"build\")\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     self.distribution.run_command(command)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 967, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     super().run_command(command)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     cmd_obj.run()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/command/build.py\", line 132, in run\r\n",
      "  \u001B[31m   \u001B[0m     self.run_command(cmd_name)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     self.distribution.run_command(command)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 967, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     super().run_command(command)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     cmd_obj.run()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/command/build_ext.py\", line 91, in run\r\n",
      "  \u001B[31m   \u001B[0m     _build_ext.run(self)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 359, in run\r\n",
      "  \u001B[31m   \u001B[0m     self.build_extensions()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 479, in build_extensions\r\n",
      "  \u001B[31m   \u001B[0m     self._build_extensions_serial()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 505, in _build_extensions_serial\r\n",
      "  \u001B[31m   \u001B[0m     self.build_extension(ext)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/5r/4mv8lcp17z90z_5v5rd13sbr0000gn/T/pip-install-8z7a2wab/sentencepiece_3187d6fd723446f6a7e54c9688991d30/setup.py\", line 87, in build_extension\r\n",
      "  \u001B[31m   \u001B[0m     subprocess.check_call(['./build_bundled.sh', __version__])\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/subprocess.py\", line 413, in check_call\r\n",
      "  \u001B[31m   \u001B[0m     raise CalledProcessError(retcode, cmd)\r\n",
      "  \u001B[31m   \u001B[0m subprocess.CalledProcessError: Command '['./build_bundled.sh', '0.1.99']' returned non-zero exit status 127.\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[31m  ERROR: Failed building wheel for sentencepiece\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[?25h  Running setup.py clean for sentencepiece\r\n",
      "Failed to build sentencepiece\r\n",
      "\u001B[31mERROR: Could not build wheels for sentencepiece, which is required to install pyproject.toml-based projects\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import promptbench as pb\n",
    "\n",
    "# print all supported datasets in promptbench\n",
    "print('All supported datasets: ')\n",
    "print(pb.SUPPORTED_DATASETS)\n",
    "\n",
    "# load a dataset, sst2, for instance.\n",
    "# if the dataset is not available locally, it will be downloaded automatically.\n",
    "dataset_name = \"gsm8k\"\n",
    "dataset = pb.DatasetLoader.load_dataset(dataset_name)\n",
    "\n",
    "# print the first 3 examples\n",
    "dataset[:3]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ic_1os-LqKww",
    "outputId": "38d64978-e8b1-4696-fac8-9484020faeaf",
    "ExecuteTime": {
     "end_time": "2024-09-02T09:35:15.069421Z",
     "start_time": "2024-09-02T09:35:14.945984Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'promptbench'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpromptbench\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpb\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# print all supported datasets in promptbench\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAll supported datasets: \u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'promptbench'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# print all supported models in promptbench\n",
    "print('All supported models: ')\n",
    "print(pb.SUPPORTED_MODELS)\n",
    "\n",
    "# load a model, gpt-3.5-turbo, for instance.\n",
    "# If model is openai/palm, need to provide openai_key/palm_key\n",
    "# If model is llama, vicuna, need to provide model dir\n",
    "model = pb.LLMModel(model='gpt-3.5-turbo',\n",
    "                    api_key = 'openai_key',\n",
    "                    max_new_tokens=150)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GboWIKBNwvnH",
    "outputId": "c0dc8535-0384-46e6-d1e7-616a38c1efe8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All supported models: \n",
      "['google/flan-t5-large', 'llama2-7b', 'llama2-7b-chat', 'llama2-13b', 'llama2-13b-chat', 'llama2-70b', 'llama2-70b-chat', 'phi-1.5', 'phi-2', 'palm', 'gpt-3.5-turbo', 'gpt-4', 'gpt-4-1106-preview', 'gpt-3.5-turbo-1106', 'gpt-4-0125-preview', 'gpt-3.5-turbo-0125', 'vicuna-7b', 'vicuna-13b', 'vicuna-13b-v1.3', 'google/flan-ul2', 'gemini-pro', 'mistralai/Mistral-7B-v0.1', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mixtral-8x7B-v0.1', 'mistralai/Mixtral-8x7B-Instruct-v0.1', '01-ai/Yi-6B', '01-ai/Yi-34B', '01-ai/Yi-6B-Chat', '01-ai/Yi-34B-Chat', 'baichuan-inc/Baichuan2-7B-Base', 'baichuan-inc/Baichuan2-13B-Base', 'baichuan-inc/Baichuan2-7B-Chat', 'baichuan-inc/Baichuan2-13B-Chat']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# load method\n",
    "# print all methods and their supported datasets\n",
    "print('All supported methods: ')\n",
    "print(pb.SUPPORTED_METHODS)\n",
    "print('Supported datasets for each method: ')\n",
    "print(pb.METHOD_SUPPORT_DATASET)\n",
    "\n",
    "# load a method, emotion_prompt, for instance.\n",
    "# https://github.com/microsoft/promptbench/tree/main/promptbench/prompt_engineering\n",
    "method = pb.PEMethod(method='emotion_prompt',\n",
    "                        dataset=dataset_name,\n",
    "                        verbose=True,  # if True, print the detailed prompt and response\n",
    "                        prompt_id = 1  # for emotion_prompt\n",
    "                        )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFPQRC6DtXQ4",
    "outputId": "67b43094-a8cd-41f0-980a-2c6e6498762a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All supported methods: \n",
      "['CoT', 'ZSCoT', 'least_to_most', 'generated_knowledge', 'expert_prompting', 'emotion_prompt', 'baseline']\n",
      "Supported datasets for each method: \n",
      "{'CoT': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'ZSCoT': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'expert_prompting': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'emotion_prompt': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'least_to_most': ['gsm8k', 'last_letter_concat'], 'generated_knowledge': ['csqa', 'numersense', 'qasc'], 'baseline': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking', 'last_letter_concat', 'numersense', 'qasc']}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "results = method.test(dataset,\n",
    "                      model,\n",
    "                      num_samples=3 # if don't set the num_samples, method will use all examples in the dataset\n",
    "                      )\n",
    "results"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAmaHUZCvqBT",
    "outputId": "4bcea33d-18c8-42d2-e81c-a06f5f9d0d75"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1/1319 [00:02<49:55,  2.27s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "This is very important to my career.\n",
      "Please output your answer at the end as ##<your answer (arabic numerals)>\n",
      "\n",
      "To find out how much Janet makes at the farmers' market every day, we first need to calculate how many eggs she has left after eating three for breakfast and using four for muffins.\n",
      "\n",
      "Janet has 16 eggs per day.\n",
      "She eats 3 for breakfast and uses 4 for muffins, so she uses 3 + 4 = 7 eggs.\n",
      "Therefore, she has 16 - 7 = 9 eggs left to sell.\n",
      "\n",
      "She sells each fresh duck egg for $2.\n",
      "So, she makes 9 * $2 = $18 every day at the farmers' market.\n",
      "\n",
      "Therefore, Janet makes $18 every day at the farmers' market.##18\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 2/1319 [00:03<36:16,  1.65s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\n",
      "This is very important to my career.\n",
      "Please output your answer at the end as ##<your answer (arabic numerals)>\n",
      "\n",
      "To make a robe, you need 2 bolts of blue fiber and half that amount of white fiber, which is 1 bolt. Therefore, in total, it takes 2 bolts of blue fiber and 1 bolt of white fiber.\n",
      "\n",
      "Adding them together, the total number of bolts needed for the robe is 2 + 1 = 3 bolts.\n",
      "\n",
      "##3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/1319 [00:05<38:49,  1.77s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\n",
      "This is very important to my career.\n",
      "Please output your answer at the end as ##<your answer (arabic numerals)>\n",
      "\n",
      "To find out how much profit Josh made, we first need to calculate the new value of the house after the repairs.\n",
      "\n",
      "The increase in value due to the repairs is 150% of the original value of the house, which is $80,000. So, the increase in value is 150/100 * $80,000 = $120,000.\n",
      "\n",
      "The new value of the house after the repairs is the original value plus the increase in value, which is $80,000 + $120,000 = $200,000.\n",
      "\n",
      "Josh's total investment in the house is the purchase price plus the cost of repairs, which is $80,000 + $50,000 = $130,000.\n",
      "\n",
      "Therefore, Josh's profit is the\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# load method\n",
    "# print all methods and their supported datasets\n",
    "print('All supported methods: ')\n",
    "print(pb.SUPPORTED_METHODS)\n",
    "print('Supported datasets for each method: ')\n",
    "print(pb.METHOD_SUPPORT_DATASET)\n",
    "\n",
    "# load a method, emotion_prompt, for instance.\n",
    "# https://github.com/microsoft/promptbench/tree/main/promptbench/prompt_engineering\n",
    "method = pb.PEMethod(method='CoT',\n",
    "                        dataset=dataset_name,\n",
    "                        verbose=True,  # if True, print the detailed prompt and response\n",
    "                        prompt_id = 1  # for emotion_prompt\n",
    "                        )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZaUgoBKvrvL",
    "outputId": "8b245892-3a09-4cba-e0e4-5a2c6d993b09"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All supported methods: \n",
      "['CoT', 'ZSCoT', 'least_to_most', 'generated_knowledge', 'expert_prompting', 'emotion_prompt', 'baseline']\n",
      "Supported datasets for each method: \n",
      "{'CoT': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'ZSCoT': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'expert_prompting': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'emotion_prompt': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'least_to_most': ['gsm8k', 'last_letter_concat'], 'generated_knowledge': ['csqa', 'numersense', 'qasc'], 'baseline': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking', 'last_letter_concat', 'numersense', 'qasc']}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "results = method.test(dataset,\n",
    "                      model,\n",
    "                      num_samples=3 # if don't set the num_samples, method will use all examples in the dataset\n",
    "                      )\n",
    "results"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-SQ6mqDyaS4",
    "outputId": "b9ef4414-d56c-4cf3-e16c-05d41c8f1d34"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1/1319 [00:01<24:43,  1.13s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\n",
      "will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have\n",
      "been 21 - 15 = 6. The answer is 6.\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A: Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they\n",
      "had 74 - 35 = 39. The answer is 39.\n",
      "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\n",
      "Jason give to Denny?\n",
      "A: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8.\n",
      "The answer is 8.\n",
      "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\n",
      "have now?\n",
      "A: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.\n",
      "The answer is 9.\n",
      "Q: There were nine computers in the server room. Five more computers were installed each day, from monday\n",
      "to thursday. How many computers are now in the server room?\n",
      "A: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20\n",
      "computers were added. 9 + 20 is 29. The answer is 29.\n",
      "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\n",
      "balls did he have at the end of wednesday?\n",
      "A: Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he\n",
      "had 35 - 2 = 33 golf balls. The answer is 33.\n",
      "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
      "A: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23\n",
      "- 15 is 8. The answer is 8.\n",
      "Q: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "A:\n",
      "\n",
      "Let's think step by step.\n",
      "Please output your answer at the end as ##<your answer (arabic numerals)>\n",
      "\n",
      "1. Janet's ducks lay 16 eggs per day.\n",
      "2. She eats 3 eggs for breakfast every morning, so she has 16 - 3 = 13 eggs remaining.\n",
      "3. She bakes muffins for her friends every day with 4 eggs, so she has 13 - 4 = 9 eggs remaining.\n",
      "4. Janet sells the remaining 9 eggs at the farmers' market for $2 per egg, so she makes 9 * 2 = $18 every day at the farmers' market.\n",
      "\n",
      "##18\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 2/1319 [00:02<21:51,  1.00it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\n",
      "will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have\n",
      "been 21 - 15 = 6. The answer is 6.\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A: Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they\n",
      "had 74 - 35 = 39. The answer is 39.\n",
      "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\n",
      "Jason give to Denny?\n",
      "A: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8.\n",
      "The answer is 8.\n",
      "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\n",
      "have now?\n",
      "A: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.\n",
      "The answer is 9.\n",
      "Q: There were nine computers in the server room. Five more computers were installed each day, from monday\n",
      "to thursday. How many computers are now in the server room?\n",
      "A: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20\n",
      "computers were added. 9 + 20 is 29. The answer is 29.\n",
      "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\n",
      "balls did he have at the end of wednesday?\n",
      "A: Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he\n",
      "had 35 - 2 = 33 golf balls. The answer is 33.\n",
      "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
      "A: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23\n",
      "- 15 is 8. The answer is 8.\n",
      "Q: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\n",
      "A:\n",
      "\n",
      "Let's think step by step.\n",
      "Please output your answer at the end as ##<your answer (arabic numerals)>\n",
      "\n",
      "1. A robe takes 2 bolts of blue fiber.\n",
      "2. It also takes half that much white fiber, which is 2 / 2 = 1 bolt.\n",
      "3. So in total, the robe takes 2 (blue) + 1 (white) = 3 bolts.\n",
      "\n",
      "Therefore, the total number of bolts it takes is 3. ##3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/1319 [00:03<28:58,  1.32s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\n",
      "will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have\n",
      "been 21 - 15 = 6. The answer is 6.\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A: Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they\n",
      "had 74 - 35 = 39. The answer is 39.\n",
      "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\n",
      "Jason give to Denny?\n",
      "A: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8.\n",
      "The answer is 8.\n",
      "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\n",
      "have now?\n",
      "A: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.\n",
      "The answer is 9.\n",
      "Q: There were nine computers in the server room. Five more computers were installed each day, from monday\n",
      "to thursday. How many computers are now in the server room?\n",
      "A: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20\n",
      "computers were added. 9 + 20 is 29. The answer is 29.\n",
      "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\n",
      "balls did he have at the end of wednesday?\n",
      "A: Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he\n",
      "had 35 - 2 = 33 golf balls. The answer is 33.\n",
      "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
      "A: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23\n",
      "- 15 is 8. The answer is 8.\n",
      "Q: Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\n",
      "A:\n",
      "\n",
      "Let's think step by step.\n",
      "Please output your answer at the end as ##<your answer (arabic numerals)>\n",
      "\n",
      "Step 1: Calculate the increase in value of the house after repairs.\n",
      "Increase in value = 150% of $80,000\n",
      "Increase in value = 150/100 * $80,000\n",
      "Increase in value = $120,000\n",
      "\n",
      "Step 2: Calculate the total value of the house after repairs.\n",
      "Total value = Initial value + Increase in value\n",
      "Total value = $80,000 + $120,000\n",
      "Total value = $200,000\n",
      "\n",
      "Step 3: Calculate the profit made by Josh.\n",
      "Profit = Total value - Cost of buying and repairs\n",
      "Profit = $200,000 - ($80,000 + $50,000)\n",
      "Profit = $200,000 - $130,000\n",
      "Profit = $\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "QOWlobl4ybyz"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
